# 版本历史

## v3.0 (2024.05.13)

### 重大变更

- **极简高效版**：彻底移除采样、样本、embedding、声纹归类等所有相关流程和代码
- **仅保留自动分轨核心功能**：基于 pyannote.audio 3.x pipeline，num_speakers=2，自动分离两位说话人音轨
- **全流程无需采样/样本/embedding**，极致高效，适合自动化和 API 集成
- **文档与依赖同步精简**：README、requirements.txt 仅保留必要内容，明确不再支持采样/样本/embedding

## v2.0 (2025.05.13)

### 新功能

- **声纹样本识别**：添加基于样本的声纹识别模块，显著提高固定主持人播客的识别准确率
- **一体化脚本**：新增`podcast_diarize.py`，整合声纹识别和分轨处理，简化用户操作流程
- **命令行参数**：提供丰富的命令行选项，支持灵活定制处理参数
- **说话人命名**：支持自定义说话人名称，使输出文件命名更友好

### 优化

- **后处理算法**：添加智能后处理，合并短片段，减少噪声干扰
- **分离参数调优**：优化 pyannote.audio 参数配置，提高基础分离质量
- **代码重构**：模块化设计，更易扩展和维护
- **统计功能**：自动计算并显示各说话人总时长

### 修复

- 修复分离后片段过于碎片化的问题
- 优化处理流程，提高执行效率

## v1.0 (2023.12.05)

### 功能

- 自动识别当前目录下的音频文件（mp3/wav）
- 使用 pyannote.audio 自动分析说话人，区分两人
- 自动生成标准格式的 JSON 时间轴文件
- 智能处理目录和文件路径，避免路径混乱
- 根据时间轴生成分离的独立音轨
- 音量处理确保与原始音频一致

### 技术细节

- 使用 FFmpeg 的 concat 分离器替代 filter_complex，解决拼接过多片段时的缓冲问题
- 实现绝对路径处理，避免目录切换导致的路径混乱
- 自动管理 HuggingFace 模型缓存，避免重复下载
- 完整错误处理，提供详细的用户指引

### 文档

- 完整的 README.md 文档，包含安装、使用和排错指南
- 详细的模型授权流程说明
- 安全建议，避免硬编码 token
